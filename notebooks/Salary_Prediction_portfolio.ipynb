{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my info here\n",
    "__author__ = \"Tomo Shimo\"\n",
    "__email__ = \"tomo.krmr@gmail.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the libraries we use\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a5f44d0bf5e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'autoreload'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some function for data loading\n",
    "\n",
    "def load_data(path, filename):\n",
    "    filepath = os.path.join(path, filename)\n",
    "    return pd.read_csv(filepath)\n",
    "\n",
    "def check_df(df):\n",
    "    # NaN \n",
    "    print('# of NaN')\n",
    "    print(df.isna().sum())\n",
    "    # Duplicate\n",
    "    print('\\n # of Duplicate')\n",
    "    print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4:43: E231 missing whitespace after ','\n",
      "7:80: E501 line too long (86 > 79 characters)\n"
     ]
    }
   ],
   "source": [
    "# some function for EDA\n",
    "\n",
    "def cat_boxplot(df, target, feature):\n",
    "    df_feature_mean = df.groupby([feature],as_index=False).mean()\n",
    "    df_feature_sorted = df_feature_mean.sort_values(by=target)\n",
    "    plt.figure()\n",
    "    sns.boxplot(x=feature, y=target, data=df, order=df_feature_sorted[feature].values)\n",
    "    plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some function for Modeling\n",
    "\n",
    "def cv_5(model, features, target):\n",
    "    # 5-fold cross validation\n",
    "    Rcross = sk.model_selection.cross_val_score(model,features,target, cv=5, scoring='neg_mean_squared_error')\n",
    "    print(model)\n",
    "    print('Mean: '+str(- Rcross.mean())+', Std: '+str(Rcross.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---- 1 Define the problem ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the salary prediction project; we predict the salary based on the job descriptions. We are going to make a model. If we obtain a new job description, we can predict the salary for this new job with using this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---- 2 Load the data ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = '~/Documents/Study/DSDJ/Instructions_and_Notebook/data/'\n",
    "df_features = load_data(csv_path, 'train_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_features.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_salaries = load_data(csv_path, 'train_salaries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_salaries.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_salaries.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we find the mismatch between data type and actual data, we'll modify it here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---- 3 Clean the data ---\n",
    "We look for duplicate data, invalid data, or corrupt data and remove it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_df(df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_df(df_salaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, salaries <= 0 are invalid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_salaries.query('salary <= 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_salaries_mod = df_salaries.query('salary > 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we marge features dataframe and salary dataframe.\n",
    "JobId is the index for these data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df_salaries_mod, df_features, how=\"inner\" ,on=\"jobId\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---- 4 Explore the data (EDA) ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before starting EDA, we are going to set some useful variables.\n",
    "# num_features: features have numerical value\n",
    "# cat_features: features have categorical value\n",
    "# target: target value\n",
    "\n",
    "num_features = ['yearsExperience', 'milesFromMetropolis']\n",
    "cat_features = ['companyId', 'jobType', 'degree', 'major', 'industry']\n",
    "target = 'salary'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# See how is the distribution of target value\n",
    "sns.distplot(df[target], 100,\"salary\", \"Distribution of salary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a long tail on the right side but it looks like a regular distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how is the correlation between target and numerical features\n",
    "from pandas.plotting import scatter_matrix\n",
    "attributes = target[:]\n",
    "attributes.extend(num_features)\n",
    "scatter_matrix(df[attributes], figsize=(12,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these analyses, salary is **positively correlated** with years of experience and **negatively correlated** with miles from metropolis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical features\n",
    "Next, we are going to see how the categorical features affect to the salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe(include='O') # 'O' means Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for feature in cat_features:\n",
    "    cat_boxplot(df, target, feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these analyses, salary is **correlated** with jobType, degree, major and industry, but looks like there's **little** correlation with companyId."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---- 5 Establish a baseline ---\n",
    "Aiming MSE < 360  \n",
    "At first, the salary considered to have a linear relationship with the years of experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lm = LinearRegression()\n",
    "lm.fit(df[['yearsExperience']],df['salary'])\n",
    "print( \"Salary = \" + str(lm.coef_[0]) + \" * yearsExperience + \" + str(lm.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_5(lm,df[['yearsExperience']],df['salary'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MSE (Mean Squared Error) is 1288."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---- 6 Hypothesize solution ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---- 7 Engineer features  ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use all the features without companyId."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features.remove('companyId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform categorical features into one-hot valiables\n",
    "\n",
    "df_num = df[num_features]\n",
    "df_cat = df[cat_features]\n",
    "df_ = df_num.join(pd.get_dummies(df_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---- 8 Create models ----\n",
    "We are using linear regression, random forest regression and gradient boosting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(df_,df[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_5(lr,df_,df[target] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest_reg = RandomForestRegressor()\n",
    "cv_5(forest_reg,df_,df[target] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "param_grid = [\n",
    "    {'n_estimators': [10,30, 100]}\n",
    "]\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(df_, df[target])\n",
    "elapsed_time = time.time() - start\n",
    "print (\"elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "forest_reg = RandomForestRegressor(n_estimators=150, n_jobs=-1)\n",
    "cv_5(forest_reg,df_,df[target] )\n",
    "elapsed_time = time.time() - start\n",
    "print (\"elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gb_reg = GradientBoostingRegressor()\n",
    "cv_5(gb_reg,df_,df[target] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "param_grid = [\n",
    "    {'n_estimators': [30, 100]}\n",
    "]\n",
    "grid_search = GridSearchCV(gb_reg, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(df_, df[target])\n",
    "elapsed_time = time.time() - start\n",
    "print (\"elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "gb_reg = GradientBoostingRegressor(n_estimators=200)\n",
    "cv_5(gb_reg,df_,df[target] )\n",
    "elapsed_time = time.time() - start\n",
    "print (\"elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "gb_reg = GradientBoostingRegressor(n_estimators=1000)\n",
    "cv_5(gb_reg,df_,df[target] )\n",
    "elapsed_time = time.time() - start\n",
    "print (\"elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance\n",
    "gb_reg_200 = GradientBoostingRegressor(n_estimators=200)\n",
    "gb_reg_200.fit(df_,df[target] )\n",
    "feature_importance = gb_reg_200.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make importances relative to max importance\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "plt.figure(figsize=(6, 10))\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, df_.columns[sorted_idx], rotation=30)\n",
    "plt.tight_layout()\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
